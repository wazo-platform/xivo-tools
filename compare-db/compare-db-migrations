#!/usr/bin/python
import StringIO
import argparse
import logging
import os
import sh
import sys
import sqlalchemy as sa

from ConfigParser import ConfigParser
from contextlib import contextmanager

from alembic.config import Config as AlembicConfig
from alembic import command as alembic_command

from xivo_dao import alchemy
from xivo_dao.helpers import db_manager

logging.basicConfig(level=logging.DEBUG)

CWD_PATH = os.path.abspath(os.path.dirname(__file__))
DB_URI = "postgres://{username}:{password}@{host}/{dbname}"

config = ConfigParser()
config.read(os.path.join(CWD_PATH, 'defaults.ini'))


def argparser():
    parser = argparse.ArgumentParser('compare XiVO database schemas and check for inconsitencies')
    parser.add_argument('--config', help='config file')
    return parser


def main():
    parser = argparser()
    args = parser.parse_args()

    if args.config:
        config.read(args.config)

    generate_installation_schema()
    generate_migration_schema()

    installed_schema = config.get('schema', 'installed')
    migrated_schema = config.get('schema', 'migrated')
    differences = compare_schemas(installed_schema, migrated_schema)

    if differences:
        print
        print "Differences detected between installed and migrated schema: "
        print
        print differences
        sys.exit(1)


def generate_installation_schema():
    schema = config.get('schema', 'installed')
    alembic_cfg = build_alembic_config()

    reset_database()
    create_tables()
    populate_db()
    #make sure stamp doesn't show up in diff
    alembic_command.stamp(alembic_cfg, 'head')
    extract_schema(schema)


def generate_migration_schema():
    schema = config.get('schema', 'migrated')
    script = os.path.join(CWD_PATH, 'asterisk_migration.sql')

    reset_database()
    run_script(script)
    run_alembic_migrations()
    extract_schema(schema)


def reset_database():
    drop_database()
    create_database()


def drop_database():
    logging.info("dropping database")

    with db_superuser():
        sql = 'DROP DATABASE IF EXISTS %s;' % config.get('database', 'dbname')
        sh.psql('-c', sql)


def create_database():
    logging.info("creating database")

    db_name = config.get('database', 'dbname')
    db_user = config.get('database', 'username')
    with db_superuser():
        sh.createdb('-E', 'utf8', '-O', db_user, db_name)


def create_tables():
    logging.info("creating tables")

    engine = sa.create_engine(sqlalchemy_url())
    db_manager.Base.metadata.create_all(bind=engine)
    db_manager.close()
    engine.dispose()


def populate_db():
    path = "{}/populate/populate.sql".format(config.get('repos', 'manage_db'))
    run_script(path)


def run_alembic_migrations():
    logging.info("running alembic migrations")
    alembic_cfg = build_alembic_config()
    alembic_command.stamp(alembic_cfg, 'base')
    alembic_command.upgrade(alembic_cfg, 'head')


def build_alembic_config():
    alembic_path = "{}/alembic".format(config.get('repos', 'manage_db'))
    ini_file = "{}/alembic.ini".format(config.get('repos', 'manage_db'))

    alembic_cfg = AlembicConfig(ini_file)
    alembic_cfg.set_main_option("script_location", alembic_path)
    alembic_cfg.set_main_option("sqlalchemy.url", sqlalchemy_url())
    return alembic_cfg


def sqlalchemy_url():
    return DB_URI.format(username=config.get('database', 'username'),
                         password=config.get('database', 'password'),
                         host=config.get('database', 'host'),
                         dbname=config.get('database', 'dbname'))


@contextmanager
def db_superuser():
    superuser = config.get('database', 'superuser')
    with sh.sudo(u=superuser, _with=True):
        yield


def run_script(filepath):
    logging.info("running script %s", filepath)

    username = config.get('database', 'username')
    database = config.get('database', 'dbname')
    error_buffer = StringIO.StringIO()

    with db_superuser():
        sh.psql(U=username, d=database, f=filepath, _err=error_buffer)

    errors = filter_errors(error_buffer)
    if errors:
        logging.warn("errors while executing %s: %s", filepath, errors)


def filter_errors(error_buffer):
    output = error_buffer.getvalue()
    errors = '\n'.join(line
                       for line in output.splitlines()
                       if 'NOTICE' not in line)
    return errors


def extract_schema(filepath):
    logging.info("extracting database schema")

    database = config.get('database', 'dbname')
    with db_superuser():
        sh.pg_dump('-s', '-f', filepath, database)


def compare_schemas(path_original, path_migrated):
    apgdiff = config.get('apgdiff', 'jar')
    logging.info("comparing %s and %s", path_original, path_migrated)
    output = sh.java('-jar', apgdiff, path_original, path_migrated)
    return unicode(output)


if __name__ == "__main__":
    main()
